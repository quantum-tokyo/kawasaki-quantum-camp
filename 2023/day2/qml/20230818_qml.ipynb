{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 量子機械学習\n",
    "\n",
    "\n",
    "Kifumi Numata (Aug 18, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 描画のため\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learnのインポート(Python用の機械学習ライブラリー)\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split # データ分割\n",
    "from sklearn.svm import SVC # SVM Classification(SVM分類)\n",
    "from sklearn.decomposition import PCA # Principal component analysis(主成分分析)\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler # 標準化、正規化のスケール変換\n",
    "\n",
    "# Qiskitのインポート\n",
    "from qiskit import Aer, execute\n",
    "from qiskit.algorithms.state_fidelities import ComputeUncompute\n",
    "from qiskit.circuit import QuantumCircuit, Parameter, ParameterVector\n",
    "from qiskit.circuit.library import PauliFeatureMap, ZFeatureMap, ZZFeatureMap\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit.primitives import Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを用意\n",
    "\n",
    "ここでは，手書き数字画像のデータセット(MNISTデータセット)から0と1のサブセットを扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数字データセットから2クラスのデータ(0と1)を読み込み\n",
    "digits = datasets.load_digits(n_class=2)   \n",
    "\n",
    "# 読み込んだ画像の最初の100枚をプロット\n",
    "fig, axes = plt.subplots(10, 10, figsize=(15, 15), subplot_kw={'xticks':[], 'yticks':[]}, gridspec_kw=dict(hspace=0.5, wspace=0.5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(digits.images[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title(digits.target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータセットには、合計360個のデータが含まれています。各データポイントは、8×8の数字の画像で、配列になっていて、各要素は0（白）から16（黒）までの整数です。古典的な分類アルゴリズムの際と同様に、データセットを学習用（40個）とテスト用（10個）のサンプルに分割し、正規化する必要があります。このデータセットを量子分類アルゴリズムに用いるために、範囲を-1から1の間にスケーリングし、次元を使用する量子ビット数（今回は4）に縮小します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの分割\n",
    "sample_train, sample_test, labels_train, labels_test = train_test_split(\n",
    "     digits.data, digits.target, test_size=0.4, random_state=22)\n",
    "\n",
    "# 次元削除\n",
    "n_dim = 4\n",
    "pca = PCA(n_components=n_dim).fit(sample_train)\n",
    "sample_train = pca.transform(sample_train)\n",
    "sample_test = pca.transform(sample_test)\n",
    "\n",
    "# 正規化\n",
    "std_scale = StandardScaler().fit(sample_train)\n",
    "sample_train = std_scale.transform(sample_train)\n",
    "sample_test = std_scale.transform(sample_test)\n",
    "\n",
    "# スケーリング\n",
    "samples = np.append(sample_train, sample_test, axis=0)\n",
    "minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "sample_train = minmax_scale.transform(sample_train)\n",
    "sample_test = minmax_scale.transform(sample_test)\n",
    "\n",
    "# 学習用40個とテスト用10個を選択\n",
    "train_size = 40\n",
    "sample_train = sample_train[:train_size]\n",
    "labels_train = labels_train[:train_size]\n",
    "\n",
    "test_size = 10\n",
    "sample_test = sample_test[:test_size]\n",
    "labels_test = labels_test[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一つ目のデータをそれぞれ表示\n",
    "print(sample_train[0], labels_train[0])\n",
    "print(sample_test[0], labels_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用データのラベルを表示\n",
    "print(labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ符号化(エンコード)\n",
    "\n",
    "この古典データを、量子特徴量マップ(ZZFeatureMap)を用いて量子状態空間にエンコードしていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4特徴量、深さ(繰り返し数)1のZZFeatureMap\n",
    "zz_map = ZZFeatureMap(feature_dimension=4, reps=1, entanglement='linear', insert_barriers=True)\n",
    "zz_map.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 量子カーネルの計算\n",
    "\n",
    "ZZFeatureMapを使って、学習データの0個目と1個目のデータについて、量子カーネルを計算する量子回路を作成し、実際に計算してみます。この値は、二つの量子状態のFidelity(忠実度)ともいいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_train[0])\n",
    "print(sample_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_map = ZZFeatureMap(feature_dimension=4, reps=1, entanglement='linear')\n",
    "qc_1 = zz_map.bind_parameters(sample_train[0])\n",
    "qc_2 = zz_map.bind_parameters(sample_train[1])\n",
    "fidelity_circuit = qc_1.copy()\n",
    "fidelity_circuit.append(qc_2.inverse().decompose(), range(fidelity_circuit.num_qubits))\n",
    "fidelity_circuit.measure_all()\n",
    "fidelity_circuit.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各回転ゲートのパラメーター値は少し読みにくいですが、回路が対称になっていることが分かると思います。左半分は訓練データsample_train[0]が、右半分は訓練データsample_train[1]がコード化されています。\n",
    "\n",
    "例として、上記の量子カーネルを測定し、ゼロ状態のカウント数の割合として、カーネル行列の要素（訓練データの0個目と1個目のデータについて）を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Aer's qasm_simulator\n",
    "from qiskit import Aer\n",
    "backend_sim = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "from qiskit import transpile\n",
    "job_sim = backend_sim.run(transpile(fidelity_circuit, backend_sim), shots=1024)\n",
    "result_sim = job_sim.result()\n",
    "counts = result_sim.get_counts(fidelity_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['0000']/sum(counts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 量子カーネル計算\n",
    "\n",
    "このプロセスを，学習データサンプルのペアごとに繰り返して学習カーネル行列を埋め，学習データサンプルとテストデータサンプルの間で繰り返してテストカーネル行列を埋めていきます。\n",
    "Qiskit Machine Learning の ``FidelityQuantumKernel`` クラスをセットアップし、 `ZZFeatureMap` を用いて量子カーネル行列を計算します。ここでは、 ``Sampler`` primitiveと、状態間のオーバーラップ(二つの状態の重なり具合)を計算する ``ComputeUncompute`` fidelityを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_map = ZZFeatureMap(feature_dimension=4, reps=1, entanglement='linear')\n",
    "sampler = Sampler()\n",
    "fidelity = ComputeUncompute(sampler=sampler)\n",
    "zz_kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=zz_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データとテストデータについて、カーネル行列を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ同士のカーネル行列計算(40x40)\n",
    "matrix_train = zz_kernel.evaluate(x_vec=sample_train)\n",
    "\n",
    "# 学習データとテストデータとのカーネル行列計算(40x10)\n",
    "matrix_test = zz_kernel.evaluate(x_vec=sample_test, y_vec=sample_train)\n",
    "\n",
    "# カーネル行列の表示\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(np.asmatrix(matrix_train),\n",
    "              interpolation='nearest', origin='upper', cmap='Blues')\n",
    "axs[0].set_title(\"training kernel matrix\")\n",
    "axs[1].imshow(np.asmatrix(matrix_test),\n",
    "              interpolation='nearest', origin='upper', cmap='Reds')\n",
    "axs[1].set_title(\"testing kernel matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "古典SVM分類器`scikit-learn`の`svc`アルゴリズムを使って学習し、テストデータで学習率を見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_svc = SVC(kernel='precomputed') #事前に計算したカーネルを使用\n",
    "zz_svc.fit(matrix_train, labels_train)  #学習データ同士のカーネルとラベルを使って学習\n",
    "\n",
    "#学習データとテストデータとのカーネル行列を使ってテストデータのラベルを予測\n",
    "label_predict = zz_svc.predict(matrix_test)\n",
    "print(label_predict, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習率を表示\n",
    "zz_score = zz_svc.score(matrix_test, labels_test) \n",
    "print(f'学習率は {zz_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストデータポイントを正しく分類できていることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 洋服画像データの分類\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで扱うデータは，MNISTデータセットの亜種である[Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist/blob/master/README.ja.md)という洋服画像データセットのサブセットです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><div><img src=\"fashion-mnist-sprite.png\" width=\"640\" /></div></center>\n",
    "\n",
    "Image source:[Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist/blob/master/README.ja.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のラベルの画像について分類します。\n",
    "\n",
    "- label 2: プルオーバー\n",
    "- label 3: ドレス\n",
    "\n",
    "まずデータセットを読み込んで，クラスごとに1枚ずつ画像を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのロード\n",
    "DATA_PATH = 'fashion.npz'\n",
    "data = np.load(DATA_PATH)\n",
    "\n",
    "sample_train = data['sample_train']\n",
    "labels_train = data['labels_train']\n",
    "sample_test = data['sample_test']\n",
    "\n",
    "# データセットの分割\n",
    "sample_train, sample_test, labels_train, labels_test = train_test_split(\n",
    "    sample_train, labels_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# データの表示\n",
    "fig = plt.figure()\n",
    "LABELS = [2,3]\n",
    "num_labels = len(LABELS)\n",
    "for i in range(num_labels):\n",
    "    ax = fig.add_subplot(2, num_labels, i+1)\n",
    "    img = sample_train[labels_train==LABELS[i]][0].reshape((28, 28))\n",
    "    ax.imshow(img, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に，以下のデータセットの前処理をします\n",
    "\n",
    "- 主成分分析(PCA)による次元圧縮\n",
    "- 正規化\n",
    "- スケーリング\n",
    "- 学習用（80個）とテスト用（20個）のサンプルを選択\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 次元削除\n",
    "N_DIM = 4\n",
    "pca = PCA(n_components=N_DIM).fit(sample_train)\n",
    "sample_train = pca.transform(sample_train)\n",
    "sample_test = pca.transform(sample_test)\n",
    "\n",
    "# 正規化\n",
    "std_scale = StandardScaler().fit(sample_train)\n",
    "sample_train = std_scale.transform(sample_train)\n",
    "sample_test = std_scale.transform(sample_test)\n",
    "\n",
    "# スケーリング\n",
    "samples = np.append(sample_train, sample_test, axis=0)\n",
    "minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "sample_train = minmax_scale.transform(sample_train)\n",
    "sample_test = minmax_scale.transform(sample_test)\n",
    "\n",
    "# 選択\n",
    "train_size = 80\n",
    "sample_train = sample_train[:train_size]\n",
    "labels_train = labels_train[:train_size]\n",
    "\n",
    "test_size = 20\n",
    "sample_test = sample_test[:test_size]\n",
    "labels_test = labels_test[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一つ目のデータをそれぞれ表示\n",
    "print(sample_train[0], labels_train[0])\n",
    "print(sample_test[0], labels_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "\n",
    "この洋服画像データについて、特徴量マップ(ZZFeatureMap)と量子カーネル(QuantumKernelクラス)を使ってカーネル行列を計算し、古典のSVMを使って学習してみます。学習率を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_map = # コードを入れてください\n",
    "zz_map.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データの0個目と1個目のデータについて、量子カーネルを計算する量子回路を作成し、実際に計算してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_train[0])\n",
    "print(sample_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_map = ZZFeatureMap(feature_dimension=4, reps=1, entanglement='linear')\n",
    "qc_1 = zz_map.bind_parameters(sample_train[0])\n",
    "qc_2 = zz_map.bind_parameters(sample_train[1])\n",
    "fidelity_circuit = qc_1.copy()\n",
    "fidelity_circuit.append(qc_2.inverse().decompose(), range(fidelity_circuit.num_qubits))\n",
    "fidelity_circuit.measure_all()\n",
    "fidelity_circuit.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Aer's qasm_simulator\n",
    "from qiskit import Aer\n",
    "backend_sim = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "from qiskit import transpile\n",
    "job_sim = backend_sim.run(transpile(fidelity_circuit, backend_sim), shots=1024)\n",
    "result_sim = job_sim.result()\n",
    "counts = result_sim.get_counts(fidelity_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['0000']/sum(counts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データとテストデータについて、QuantumKernelクラスを使ってカーネル行列を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler()\n",
    "fidelity = # コードを入れてください\n",
    "zz_kernel = # コードを入れてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train = # コードを入れてください\n",
    "matrix_test = # コードを入れてください\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(np.asmatrix(matrix_train),\n",
    "              interpolation='nearest', origin='upper', cmap='Blues')\n",
    "axs[0].set_title(\"training kernel matrix\")\n",
    "axs[1].imshow(np.asmatrix(matrix_test),\n",
    "              interpolation='nearest', origin='upper', cmap='Reds')\n",
    "axs[1].set_title(\"testing kernel matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "古典SVM分類器`scikit-learn`の`svc`アルゴリズムを使って学習し、テストデータで学習率を見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_svc = # コードを入れてください\n",
    "zz_svc.fit(matrix_train, labels_train) #学習データ同士のカーネルとラベルを使って学習\n",
    "\n",
    "#学習データとテストデータとのカーネル行列を使ってテストデータのラベルを予測\n",
    "label_predict = # コードを入れてください\n",
    "print(label_predict, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習率を表示\n",
    "zz_score = zz_svc.score(matrix_test, labels_test) \n",
    "print(f'学習率は {zz_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 時間の余った方向け\n",
    "\n",
    "データセットunknown_dataが プルオーバー（ラベル2）、またはドレス（ラベル3）、どちらのデータセットであるかを学習した量子カーネル行列を使って、SVMで判別してください。データunknown_dataは、10個の同じラベルのデータセットを次元削除、正規化、スケーリングしたものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_data =[[-0.7506181229786677, 0.3639757115940703, -0.40259035779756747, 0.13156494990059703],\n",
    "               [0.6876543623856463, -0.14395585615940995, -1.0, 0.18833132593453705],\n",
    "               [0.1597345117739556, 0.037029365985354834, -0.74170020071629, -0.35871272660416686],\n",
    "               [0.12415150114857995, 0.15427446808127593, 0.08476843970362899, -0.6089690897810438],\n",
    "               [0.5488865570214291, 0.17113499449186953, -0.06577365245877217, -0.17285785841016588],\n",
    "               [-0.5332555688379076, 0.5395437640172006, -0.3128336939755401, -0.6498356127249841],\n",
    "               [0.8161223476490759, -0.20027533959873733, -0.21196321310952376, -0.1737145763437467],\n",
    "               [0.4625041945567496, 0.1150438935335493, 0.02083253784257244, -0.20607780130264472],\n",
    "               [0.6477170524202525, -0.3435526101878924, -0.5108689103689058, -0.3800636730989028],\n",
    "               [-0.09984118916814182, 0.4890014133606272, -0.14802829167372678, -0.18753891291420458]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとunknown_dataデータとのカーネル行列(80x10)を計算します\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとunknown_dataデータとのカーネル行列を使って\n",
    "# unknown_dataデータのラベルを予測します\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit.tools.jupyter\n",
    "%qiskit_version_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
