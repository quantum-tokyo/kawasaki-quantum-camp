{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 量子機械学習\n",
    "\n",
    "\n",
    "Kifumi Numata (Aug 02, 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 描画のため\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learnのインポート(Python用の機械学習ライブラリー)\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split # データ分割\n",
    "from sklearn.svm import SVC # SVM Classification(SVM分類)\n",
    "from sklearn.decomposition import PCA # Principal component analysis(主成分分析)\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler # 標準化、正規化のスケール変換\n",
    "\n",
    "# Qiskitのインポート\n",
    "from qiskit import Aer, execute\n",
    "from qiskit.circuit import QuantumCircuit, Parameter, ParameterVector\n",
    "from qiskit.circuit.library import PauliFeatureMap, ZFeatureMap, ZZFeatureMap\n",
    "from qiskit_machine_learning.kernels import QuantumKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを用意\n",
    "\n",
    "ここでは，手書き数字画像のデータセット(MNISTデータセット)から0と1のサブセットを扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数字データセットから2クラスのデータ(0と1)を読み込み\n",
    "digits = datasets.load_digits(n_class=2)   \n",
    "\n",
    "# 読み込んだ画像の最初の100枚をプロット\n",
    "fig, axes = plt.subplots(10, 10, figsize=(15, 15), subplot_kw={'xticks':[], 'yticks':[]}, gridspec_kw=dict(hspace=0.5, wspace=0.5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(digits.images[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title(digits.target[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータセットには、合計360個のデータが含まれています。各データポイントは、8×8の数字の画像で、配列になっていて、各要素は0（白）から16（黒）までの整数です。古典的な分類アルゴリズムの際と同様に、データセットを学習用（100）とテスト用（20）のサンプルに分割し、正規化する必要があります。このデータセットを量子分類アルゴリズムに用いるために、範囲を-1から1の間にスケーリングし、次元を使用する量子ビット数（今回は4）に縮小します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの分割\n",
    "sample_train, sample_test, labels_train, labels_test = train_test_split(\n",
    "     digits.data, digits.target, test_size=0.2, random_state=22)\n",
    "\n",
    "# 次元削除\n",
    "n_dim = 4\n",
    "pca = PCA(n_components=n_dim).fit(sample_train)\n",
    "sample_train = pca.transform(sample_train)\n",
    "sample_test = pca.transform(sample_test)\n",
    "\n",
    "# 標準化\n",
    "std_scale = StandardScaler().fit(sample_train)\n",
    "sample_train = std_scale.transform(sample_train)\n",
    "sample_test = std_scale.transform(sample_test)\n",
    "\n",
    "# 正規化\n",
    "samples = np.append(sample_train, sample_test, axis=0)\n",
    "minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "sample_train = minmax_scale.transform(sample_train)\n",
    "sample_test = minmax_scale.transform(sample_test)\n",
    "\n",
    "# 学習用100個とテスト用20個を選択\n",
    "train_size = 100\n",
    "sample_train = sample_train[:train_size]\n",
    "labels_train = labels_train[:train_size]\n",
    "\n",
    "test_size = 20\n",
    "sample_test = sample_test[:test_size]\n",
    "labels_test = labels_test[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一つ目のデータをそれぞれ表示\n",
    "print(sample_train[0], labels_train[0])\n",
    "print(sample_test[0], labels_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ符号化(エンコード)\n",
    "\n",
    "この古典データを、量子特徴量マップ(ZZFeatureMap)を用いて量子状態空間にエンコードしていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4特徴量、深さ(繰り返し数)1のZZFeatureMap\n",
    "zz_map = ZZFeatureMap(feature_dimension=4, reps=1, entanglement='linear', insert_barriers=True)\n",
    "zz_map.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量子カーネル計算\n",
    "\n",
    "量子特徴マップ$\\phi(\\vec{x})$は、量子カーネル$k(\\vec{x}_i,\\vec{x}_j)= \\phi(\\vec{x}_j)^\\dagger\\phi(\\vec{x}_i)$を作ることができます。これは類似性の尺度と考えることができ、$\\vec{x}_i$ と $\\vec{x}_j$が近いときに大きくなります。\n",
    "\n",
    "今回は、ZZFeatureMapを使って量子カーネルを計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_kernel = QuantumKernel(feature_map=zz_map, quantum_instance=Aer.get_backend('statevector_simulator'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データの0個目と1個目のデータについて、量子カーネルを計算する量子回路を作成し、実際に計算してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_train[0])\n",
    "print(sample_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_circuit = zz_kernel.construct_circuit(sample_train[0], sample_train[1])\n",
    "zz_circuit.decompose().decompose().draw(output='mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各回転ゲートのパラメーター値は少し読みにくいですが、回路が対称になっていることが分かると思います。左半分は訓練データsample_train[0]が、右半分は訓練データsample_train[1]がコード化されています。\n",
    "\n",
    "例として、上記の量子カーネルを測定し、ゼロ状態のカウント数の割合として、カーネル行列の要素（訓練データの0個目と1個目のデータについて）を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "job = execute(zz_circuit, backend, shots=8192, \n",
    "              seed_simulator=1024, seed_transpiler=1024)\n",
    "counts = job.result().get_counts(zz_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['0000']/sum(counts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このプロセスを，学習データサンプルのペアごとに繰り返して学習カーネル行列を埋め，学習データサンプルとテストデータサンプルの間で繰り返してテストカーネル行列を埋めていきます。なお，各行列は対称形であるため，計算時間を短縮するために，要素の半分だけを計算しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データとテストデータについて、QuantumKernelクラスを使ってカーネル行列を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train = zz_kernel.evaluate(x_vec=sample_train)\n",
    "matrix_test = zz_kernel.evaluate(x_vec=sample_test, y_vec=sample_train)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(np.asmatrix(matrix_train),\n",
    "              interpolation='nearest', origin='upper', cmap='Blues')\n",
    "axs[0].set_title(\"training kernel matrix\")\n",
    "axs[1].imshow(np.asmatrix(matrix_test),\n",
    "              interpolation='nearest', origin='upper', cmap='Reds')\n",
    "axs[1].set_title(\"testing kernel matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "古典SVM分類器`scikit-learn`の`svc`アルゴリズムを使って学習し、テストデータで学習率を見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zzpc_svc = SVC(kernel='precomputed')\n",
    "zzpc_svc.fit(matrix_train, labels_train)\n",
    "zzpc_score = zzpc_svc.score(matrix_test, labels_test)\n",
    "\n",
    "print(f'Kernel classification test score: {zzpc_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストデータポイントをほぼ正しく分類できていることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 洋服画像データの分類\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで扱うデータは，MNISTデータセットの亜種である[Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist/blob/master/README.ja.md)という洋服画像データセットのサブセットです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><div><img src=\"fashion-mnist-sprite.png\" width=\"640\" /></div></center>\n",
    "\n",
    "Image source:[Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist/blob/master/README.ja.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のラベルの画像について分類します。\n",
    "\n",
    "- label 2: プルオーバー\n",
    "- label 3: ドレス\n",
    "\n",
    "まずデータセットを読み込んで，クラスごとに1枚ずつ画像を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import cm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Scikit-learnのインポート(Python用の機械学習ライブラリー)\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Qiskitのインポート\n",
    "from qiskit import Aer, execute\n",
    "from qiskit.circuit import QuantumCircuit, Parameter, ParameterVector\n",
    "from qiskit.circuit.library import PauliFeatureMap, ZFeatureMap, ZZFeatureMap\n",
    "from qiskit.circuit.library import TwoLocal, NLocal, RealAmplitudes, EfficientSU2\n",
    "from qiskit.circuit.library import HGate, RXGate, RYGate, RZGate, CXGate, CRXGate, CRZGate\n",
    "from qiskit_machine_learning.kernels import QuantumKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのロード\n",
    "DATA_PATH = 'fashion.npz'\n",
    "data = np.load(DATA_PATH)\n",
    "\n",
    "sample_train = data['sample_train']\n",
    "labels_train = data['labels_train']\n",
    "sample_test = data['sample_test']\n",
    "\n",
    "# データセットの分割\n",
    "sample_train, sample_test, labels_train, labels_test = train_test_split(\n",
    "    sample_train, labels_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# データの表示\n",
    "fig = plt.figure()\n",
    "LABELS = [2,3]\n",
    "num_labels = len(LABELS)\n",
    "for i in range(num_labels):\n",
    "    ax = fig.add_subplot(2, num_labels, i+1)\n",
    "    img = sample_train[labels_train==LABELS[i]][0].reshape((28, 28))\n",
    "    ax.imshow(img, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に，以下のデータセットの前処理をします\n",
    "\n",
    "- 標準化\n",
    "- 主成分分析(PCA)による次元圧縮\n",
    "- 正規化\n",
    "\n",
    "なおN_DIMを変えることで，次元数を変えることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 次元削除\n",
    "N_DIM = 4\n",
    "pca = PCA(n_components=N_DIM).fit(sample_train)\n",
    "sample_train = pca.transform(sample_train)\n",
    "sample_test = pca.transform(sample_test)\n",
    "\n",
    "# 標準化\n",
    "std_scale = StandardScaler().fit(sample_train)\n",
    "sample_train = std_scale.transform(sample_train)\n",
    "sample_test = std_scale.transform(sample_test)\n",
    "\n",
    "# 正規化\n",
    "samples = np.append(sample_train, sample_test, axis=0)\n",
    "minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "sample_train = minmax_scale.transform(sample_train)\n",
    "sample_test = minmax_scale.transform(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一つ目のデータをそれぞれ表示\n",
    "print(sample_train[0], labels_train[0])\n",
    "print(sample_test[0], labels_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "\n",
    "この洋服画像データについて、特徴量マップ(ZZFeatureMap)と量子カーネル(QuantumKernelクラス)を使ってカーネル行列を計算し、古典のSVMを使って学習してみます。学習率を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
